{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import re\n",
    "from string import punctuation\n",
    "import time\n",
    "from nltk import tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from gensim import corpora, models\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem de Assuntos\n",
    "1. Usando a biblioteca Gensim, treine um modelo LSI e LDA para o seu corpus propondo uma metodologia para otimizaçao do numero de assuntos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lendo a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient = 'index')\n",
    "\n",
    "df = getDF('reviews_Video_Games_5.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizando o texto, colocando em caixa baixa, removendo stop words, termos de um caracter e termos que apareceram menos do que 20 vezes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos = list(df['reviewText'])\n",
    "\n",
    "sw = stopwords.words('english') + list(punctuation)\n",
    "\n",
    "textos_limpos = []\n",
    "c = Counter([])\n",
    "for texto in textos:\n",
    "    tlimpo = [token.lower() for token in tokenize.TweetTokenizer().tokenize(texto) if token.lower() not in sw]\n",
    "    c.update(tlimpo)\n",
    "    textos_limpos.append(tlimpo)\n",
    "\n",
    "ps = PorterStemmer()\n",
    "stemmed = []\n",
    "for t in textos_limpos:\n",
    "    txt = [ps.stem(token) for token in t]\n",
    "    stemmed.append(txt)\n",
    "stemmed = [[token for token in t if (c[token] >= 1000 and len(token) > 1)] for t in stemmed]\n",
    "\n",
    "dicionario = corpora.Dictionary(stemmed)\n",
    "\n",
    "corpus = [dicionario.doc2bow(d) for d in stemmed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustando vários modelos lsi e lda e verificando a medida de coerência deles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "lsi = []\n",
    "lda = []\n",
    "co_lsi = []\n",
    "co_lda = []\n",
    "for i in range(2, 16): \n",
    "    print(i)\n",
    "    tmp_lsi = models.LsiModel(corpus, id2word = dicionario, num_topics = i)\n",
    "    coherencemodel = CoherenceModel(model = tmp_lsi, texts = textos_limpos, dictionary = dicionario, coherence = 'c_v')\n",
    "    lsi.append(tmp_lsi)\n",
    "    co_lsi.append(coherencemodel.get_coherence())\n",
    "    tmp_lda = models.LdaModel(corpus, id2word = dicionario, num_topics = i)\n",
    "    coherencemodel = CoherenceModel(model = tmp_lda, texts = textos_limpos, dictionary = dicionario, coherence = 'c_v')\n",
    "    lda.append(tmp_lda)\n",
    "    co_lda.append(coherencemodel.get_coherence())\n",
    "end_time = time.time()\n",
    "end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecionando o número adequado de tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(2,16)), co_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "co_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(2,16)), co_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lsi = lsi[10]\n",
    "best_lda = lda[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lsi.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
